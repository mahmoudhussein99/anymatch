trainable params: 124441344
--------------------------------------------------
Experiment to leave the wdc-computers dataset out with attr+row as training data.
The model will be trained on the mixture of attribute and row level data.
The training set size of wdc-shoes is larger than 1200, we will do down-sampling with automl_filter to maximally 1200 pairs.
The training set size of wdc-watches is larger than 1200, we will do down-sampling with automl_filter to maximally 1200 pairs.
The training set size of wdc-cameras is larger than 1200, we will do down-sampling with automl_filter to maximally 1200 pairs.
The training set size of dbgo is larger than 1200, we will do down-sampling with automl_filter to maximally 1200 pairs.
The training set size of music is larger than 1200, we will do down-sampling with automl_filter to maximally 1200 pairs.
Examples(row level) after the serialization are:

Record A is <p>COL nike air zoom structure 19 para mujer violeta azul zapatillas, COL N/A, COL N/A</p>. Record B is <p>COL nike femme air zoom pegasus 33 violet blanc rose chaussures pour, COL unit s nike zoom air au talon et l avant pied pour plus de dynamismemesh tiss favorisant la circulation d air fraisc bles flywire maintenant le piedsemelle interm diaire en cushlon pour plus d amorti, COL N/A</p>. Given the attributes of the two records, are they the same?
Record A is <p>COL junghans men s meister chronoscope automatic chronograph watch 027 4324 44 shop com, COL meister is junghans expression of the style of their classic watches while staying true to the principles of the finest materials and technological improvements refined aesthetics reminiscent of the watches designed by anton ziegler for the brand between 1930 and 1960 inside the watch is an automatic self winding chronograph j880 2 movement with 30 minute and 12 hour counters for the chronograph as well as sub second and day and date function this is displayed on a sunray brushed dark grey dial with hour and minutes marked clearly and simply the case is a stainless steel construction featuring exhibition case back with curved sicralan coated hard plexiglass true to the original giving it an elegant curvature to the dial the watch fastens on a 9 link stainless steel bracelet polished and matte finished for a perfect accompaniment to the case and dial, COL N/A</p>. Record B is <p>COL men s chronograph 1972 chronoscope solar junghans nur 749 00, COL N/A, COL junghans</p>. Given the attributes of the two records, are they the same?
Record A is <p>COL canon 1133b001aa cb 2lx battery charger from solid signal, COL the canon cb 2lx compact battery charger is designed to take full advantage of high capacity rechargeable batteries it has been specially designed to charge the canon nb 5l battery, COL canon</p>. Record B is <p>COL cnd1133b001aa canon cb 2lx battery charger camera photo accessories page 2121 all tech toys, COL the cb 2lx battery charger charges canon nb 5l batteries allowing you to charge an additional battery for your digital camera, COL canon</p>. Given the attributes of the two records, are they the same?
Record A is <p>COL sql/xml is making good progress, COL a eisenberg , j melton</p>. Record B is <p>COL sql/xml is making good progress, COL a eisenberg , j melton</p>. Given the attributes of the two records, are they the same?
Record A is <p>COL Takin' My Time (Kiss My Amps Live), COL Tom Petty and the Heartbreakers, COL Kiss My Amps Live, COL 2011</p>. Record B is <p>COL 005-Nowhere, ca, COL The Sore Thumbs, COL Listen Up!! (2006), COL N/A</p>. Given the attributes of the two records, are they the same?
The size of the row level concatenation for training, validation, and test are: 6000, 11918, 12291
1517 out of 11027 data samples are filtered.
1083 out of 11918 data samples are filtered.
The training phase starts from here.
The size of the training and validation datasets are: 9510, 10835
Here is the configuration for the experiment:
	seed: 42	base_model: gpt2	dataset_name: wdc-computers	mode: mode1 	max_len: 350	lr: 2e-05	batch_size: 32	patience: 6	p_start: 20
Epoch: 1 | Train Loss: 0.4675 | Valid Loss: 0.1670 | Train acc: 81.10 | Valid acc: 93.80 | Train f1: 75.27 | Valid f1: 88.54 | Train Time: 130.71970796585083 secs
The best model is updated at epoch: 1 with f1 score 0.8853974121996303
Epoch: 2 | Train Loss: 0.2519 | Valid Loss: 0.0983 | Train acc: 90.01 | Valid acc: 96.90 | Train f1: 87.53 | Valid f1: 94.62 | Train Time: 127.8462016582489 secs
The best model is updated at epoch: 2 with f1 score 0.9461805555555556
Epoch: 3 | Train Loss: 0.1943 | Valid Loss: 0.0907 | Train acc: 92.12 | Valid acc: 96.60 | Train f1: 90.22 | Valid f1: 93.87 | Train Time: 126.3040030002594 secs
Epoch: 4 | Train Loss: 0.1629 | Valid Loss: 0.1065 | Train acc: 93.69 | Valid acc: 96.25 | Train f1: 92.24 | Valid f1: 93.65 | Train Time: 128.24450206756592 secs
Epoch: 5 | Train Loss: 0.1293 | Valid Loss: 0.1357 | Train acc: 95.07 | Valid acc: 96.25 | Train f1: 93.95 | Valid f1: 93.31 | Train Time: 126.57698011398315 secs
Epoch: 6 | Train Loss: 0.1094 | Valid Loss: 0.1389 | Train acc: 95.86 | Valid acc: 96.65 | Train f1: 94.94 | Valid f1: 93.97 | Train Time: 128.26815366744995 secs
Epoch: 7 | Train Loss: 0.0983 | Valid Loss: 0.1351 | Train acc: 96.52 | Valid acc: 96.55 | Train f1: 95.75 | Valid f1: 94.16 | Train Time: 127.77994680404663 secs
Epoch: 8 | Train Loss: 0.0783 | Valid Loss: 0.1845 | Train acc: 97.36 | Valid acc: 96.75 | Train f1: 96.79 | Valid f1: 94.49 | Train Time: 127.76668953895569 secs
Epoch: 9 | Train Loss: 0.0691 | Valid Loss: 0.2265 | Train acc: 97.91 | Valid acc: 96.55 | Train f1: 97.46 | Valid f1: 93.93 | Train Time: 127.37245297431946 secs
Epoch: 10 | Train Loss: 0.0570 | Valid Loss: 0.2390 | Train acc: 98.00 | Valid acc: 96.25 | Train f1: 97.57 | Valid f1: 93.46 | Train Time: 128.10748720169067 secs
Epoch: 11 | Train Loss: 0.0511 | Valid Loss: 0.3566 | Train acc: 98.49 | Valid acc: 95.45 | Train f1: 98.16 | Valid f1: 92.11 | Train Time: 127.46300959587097 secs
Epoch: 12 | Train Loss: 0.0433 | Valid Loss: 0.2007 | Train acc: 98.78 | Valid acc: 97.10 | Train f1: 98.52 | Valid f1: 94.77 | Train Time: 127.08939695358276 secs
The best model is updated at epoch: 12 with f1 score 0.9476534296028881
Epoch: 13 | Train Loss: 0.0405 | Valid Loss: 0.2132 | Train acc: 99.00 | Valid acc: 97.00 | Train f1: 98.79 | Valid f1: 94.81 | Train Time: 127.69067335128784 secs
The best model is updated at epoch: 13 with f1 score 0.9480968858131488
Epoch: 14 | Train Loss: 0.0331 | Valid Loss: 0.3272 | Train acc: 99.11 | Valid acc: 96.65 | Train f1: 98.92 | Valid f1: 93.87 | Train Time: 127.7365174293518 secs
Epoch: 15 | Train Loss: 0.0336 | Valid Loss: 0.2772 | Train acc: 99.02 | Valid acc: 96.20 | Train f1: 98.81 | Valid f1: 93.09 | Train Time: 127.77608752250671 secs
Epoch: 16 | Train Loss: 0.0249 | Valid Loss: 0.3144 | Train acc: 99.35 | Valid acc: 96.70 | Train f1: 99.21 | Valid f1: 94.36 | Train Time: 127.21332836151123 secs
Epoch: 17 | Train Loss: 0.0276 | Valid Loss: 0.5055 | Train acc: 99.21 | Valid acc: 95.20 | Train f1: 99.04 | Valid f1: 91.86 | Train Time: 127.21423244476318 secs
Epoch: 18 | Train Loss: 0.0243 | Valid Loss: 0.2343 | Train acc: 99.34 | Valid acc: 96.80 | Train f1: 99.20 | Valid f1: 94.51 | Train Time: 125.85915112495422 secs
Epoch: 19 | Train Loss: 0.0259 | Valid Loss: 0.3440 | Train acc: 99.15 | Valid acc: 96.50 | Train f1: 98.97 | Valid f1: 93.89 | Train Time: 126.38227200508118 secs
Epoch: 20 | Train Loss: 0.0188 | Valid Loss: 0.3192 | Train acc: 99.50 | Valid acc: 96.45 | Train f1: 99.39 | Valid f1: 93.85 | Train Time: 127.03987789154053 secs
Epoch: 21 | Train Loss: 0.0208 | Valid Loss: 0.5009 | Train acc: 99.53 | Valid acc: 95.50 | Train f1: 99.43 | Valid f1: 92.41 | Train Time: 127.97882103919983 secs
Epoch: 22 | Train Loss: 0.0235 | Valid Loss: 0.3526 | Train acc: 99.43 | Valid acc: 96.55 | Train f1: 99.31 | Valid f1: 94.18 | Train Time: 126.65280532836914 secs
Early stopping at epoch: 22
The training phase is finished.
Start the evaluation phase.
0 out of 1100 data samples are filtered.
trainable params: 124441344
--------------------------------------------------
Experiment to leave the wdc-shoes dataset out with attr+row as training data.
The model will be trained on the mixture of attribute and row level data.
The training set size of wdc-computers is larger than 1200, we will do down-sampling with automl_filter to maximally 1200 pairs.
The training set size of wdc-watches is larger than 1200, we will do down-sampling with automl_filter to maximally 1200 pairs.
The training set size of wdc-cameras is larger than 1200, we will do down-sampling with automl_filter to maximally 1200 pairs.
The training set size of dbgo is larger than 1200, we will do down-sampling with automl_filter to maximally 1200 pairs.
The training set size of music is larger than 1200, we will do down-sampling with automl_filter to maximally 1200 pairs.
Examples(row level) after the serialization are:

Record A is <p>COL targus notebook backpac 15 4 zwart grijs prijzen tweakers, COL N/A, COL N/A</p>. Record B is <p>COL amazonbasics 13 3 inch laptop sleeve black carrying cases page 10 office outlet express, COL the amazonbasics 13 3 inch laptop sleeve provides stylish protection for your laptop or ultrabook protect your laptop from bumps and scratches, COL amazonbasics</p>. Given the attributes of the two records, are they the same?
Record A is <p>COL junghans men s meister chronoscope automatic chronograph watch 027 4324 44 shop com, COL meister is junghans expression of the style of their classic watches while staying true to the principles of the finest materials and technological improvements refined aesthetics reminiscent of the watches designed by anton ziegler for the brand between 1930 and 1960 inside the watch is an automatic self winding chronograph j880 2 movement with 30 minute and 12 hour counters for the chronograph as well as sub second and day and date function this is displayed on a sunray brushed dark grey dial with hour and minutes marked clearly and simply the case is a stainless steel construction featuring exhibition case back with curved sicralan coated hard plexiglass true to the original giving it an elegant curvature to the dial the watch fastens on a 9 link stainless steel bracelet polished and matte finished for a perfect accompaniment to the case and dial, COL N/A</p>. Record B is <p>COL men s chronograph 1972 chronoscope solar junghans nur 749 00, COL N/A, COL junghans</p>. Given the attributes of the two records, are they the same?
Record A is <p>COL canon 1133b001aa cb 2lx battery charger from solid signal, COL the canon cb 2lx compact battery charger is designed to take full advantage of high capacity rechargeable batteries it has been specially designed to charge the canon nb 5l battery, COL canon</p>. Record B is <p>COL cnd1133b001aa canon cb 2lx battery charger camera photo accessories page 2121 all tech toys, COL the cb 2lx battery charger charges canon nb 5l batteries allowing you to charge an additional battery for your digital camera, COL canon</p>. Given the attributes of the two records, are they the same?
Record A is <p>COL sql/xml is making good progress, COL a eisenberg , j melton</p>. Record B is <p>COL sql/xml is making good progress, COL a eisenberg , j melton</p>. Given the attributes of the two records, are they the same?
Record A is <p>COL Takin' My Time (Kiss My Amps Live), COL Tom Petty and the Heartbreakers, COL Kiss My Amps Live, COL 2011</p>. Record B is <p>COL 005-Nowhere, ca, COL The Sore Thumbs, COL Listen Up!! (2006), COL N/A</p>. Given the attributes of the two records, are they the same?
The size of the row level concatenation for training, validation, and test are: 6000, 12438, 12292
1020 out of 11168 data samples are filtered.
826 out of 12438 data samples are filtered.
The training phase starts from here.
The size of the training and validation datasets are: 10148, 11612
Here is the configuration for the experiment:
	seed: 42	base_model: gpt2	dataset_name: wdc-shoes	mode: mode1 	max_len: 350	lr: 2e-05	batch_size: 32	patience: 6	p_start: 20
Epoch: 1 | Train Loss: 0.3981 | Valid Loss: 0.1503 | Train acc: 80.98 | Valid acc: 94.60 | Train f1: 75.30 | Valid f1: 90.27 | Train Time: 132.10606813430786 secs
The best model is updated at epoch: 1 with f1 score 0.9027027027027027
Epoch: 2 | Train Loss: 0.2265 | Valid Loss: 0.0916 | Train acc: 90.83 | Valid acc: 96.65 | Train f1: 88.56 | Valid f1: 93.76 | Train Time: 132.81606674194336 secs
The best model is updated at epoch: 2 with f1 score 0.9375582479030755
Epoch: 3 | Train Loss: 0.1855 | Valid Loss: 0.0895 | Train acc: 92.82 | Valid acc: 96.40 | Train f1: 91.14 | Valid f1: 93.09 | Train Time: 131.75080466270447 secs
Epoch: 4 | Train Loss: 0.1485 | Valid Loss: 0.1044 | Train acc: 94.27 | Valid acc: 96.55 | Train f1: 92.96 | Valid f1: 93.70 | Train Time: 132.45055866241455 secs
Epoch: 5 | Train Loss: 0.1235 | Valid Loss: 0.1259 | Train acc: 95.51 | Valid acc: 95.95 | Train f1: 94.52 | Valid f1: 92.89 | Train Time: 131.78964757919312 secs
Epoch: 6 | Train Loss: 0.1067 | Valid Loss: 0.1104 | Train acc: 95.98 | Valid acc: 96.30 | Train f1: 95.10 | Valid f1: 93.39 | Train Time: 132.1817171573639 secs
Epoch: 7 | Train Loss: 0.0878 | Valid Loss: 0.2144 | Train acc: 97.05 | Valid acc: 95.30 | Train f1: 96.41 | Valid f1: 91.55 | Train Time: 131.25268125534058 secs
Epoch: 8 | Train Loss: 0.0794 | Valid Loss: 0.1323 | Train acc: 97.33 | Valid acc: 97.00 | Train f1: 96.76 | Valid f1: 94.20 | Train Time: 131.79331970214844 secs
The best model is updated at epoch: 8 with f1 score 0.941972920696325
Epoch: 9 | Train Loss: 0.0682 | Valid Loss: 0.2215 | Train acc: 97.71 | Valid acc: 96.05 | Train f1: 97.23 | Valid f1: 93.00 | Train Time: 131.56146502494812 secs
Epoch: 10 | Train Loss: 0.0543 | Valid Loss: 0.1364 | Train acc: 98.31 | Valid acc: 97.45 | Train f1: 97.96 | Valid f1: 95.49 | Train Time: 131.6680507659912 secs
The best model is updated at epoch: 10 with f1 score 0.9549071618037135
Epoch: 11 | Train Loss: 0.0508 | Valid Loss: 0.2220 | Train acc: 98.47 | Valid acc: 95.90 | Train f1: 98.15 | Valid f1: 92.94 | Train Time: 131.7835774421692 secs
Epoch: 12 | Train Loss: 0.0492 | Valid Loss: 0.2120 | Train acc: 98.54 | Valid acc: 96.45 | Train f1: 98.23 | Valid f1: 93.81 | Train Time: 131.82117581367493 secs
Epoch: 13 | Train Loss: 0.0416 | Valid Loss: 0.2498 | Train acc: 98.81 | Valid acc: 95.80 | Train f1: 98.55 | Valid f1: 92.67 | Train Time: 132.3766462802887 secs
Epoch: 14 | Train Loss: 0.0382 | Valid Loss: 0.2782 | Train acc: 98.89 | Valid acc: 95.30 | Train f1: 98.65 | Valid f1: 91.50 | Train Time: 132.44968962669373 secs
Epoch: 15 | Train Loss: 0.0333 | Valid Loss: 0.2175 | Train acc: 98.93 | Valid acc: 97.15 | Train f1: 98.70 | Valid f1: 94.46 | Train Time: 130.2362072467804 secs
Epoch: 16 | Train Loss: 0.0315 | Valid Loss: 0.2199 | Train acc: 99.10 | Valid acc: 96.40 | Train f1: 98.91 | Valid f1: 93.06 | Train Time: 130.5603630542755 secs
Epoch: 17 | Train Loss: 0.0299 | Valid Loss: 0.2077 | Train acc: 99.16 | Valid acc: 96.45 | Train f1: 98.98 | Valid f1: 94.10 | Train Time: 132.4028103351593 secs
Epoch: 18 | Train Loss: 0.0298 | Valid Loss: 0.2579 | Train acc: 99.21 | Valid acc: 96.20 | Train f1: 99.04 | Valid f1: 93.17 | Train Time: 133.09868836402893 secs
Epoch: 19 | Train Loss: 0.0269 | Valid Loss: 0.2514 | Train acc: 99.22 | Valid acc: 96.50 | Train f1: 99.06 | Valid f1: 94.11 | Train Time: 131.64507865905762 secs
Epoch: 20 | Train Loss: 0.0221 | Valid Loss: 0.2791 | Train acc: 99.45 | Valid acc: 96.40 | Train f1: 99.33 | Valid f1: 93.62 | Train Time: 133.0438997745514 secs
Epoch: 21 | Train Loss: 0.0208 | Valid Loss: 0.3312 | Train acc: 99.40 | Valid acc: 96.05 | Train f1: 99.27 | Valid f1: 93.34 | Train Time: 132.91500544548035 secs
Epoch: 22 | Train Loss: 0.0205 | Valid Loss: 0.2992 | Train acc: 99.49 | Valid acc: 95.85 | Train f1: 99.38 | Valid f1: 92.49 | Train Time: 131.86220145225525 secs
Early stopping at epoch: 22
The training phase is finished.
Start the evaluation phase.
0 out of 1100 data samples are filtered.
trainable params: 124441344
--------------------------------------------------
Experiment to leave the wdc-watches dataset out with attr+row as training data.
The model will be trained on the mixture of attribute and row level data.
The training set size of wdc-computers is larger than 1200, we will do down-sampling with automl_filter to maximally 1200 pairs.
The training set size of wdc-shoes is larger than 1200, we will do down-sampling with automl_filter to maximally 1200 pairs.
The training set size of wdc-cameras is larger than 1200, we will do down-sampling with automl_filter to maximally 1200 pairs.
The training set size of dbgo is larger than 1200, we will do down-sampling with automl_filter to maximally 1200 pairs.
The training set size of music is larger than 1200, we will do down-sampling with automl_filter to maximally 1200 pairs.
Examples(row level) after the serialization are:

Record A is <p>COL targus notebook backpac 15 4 zwart grijs prijzen tweakers, COL N/A, COL N/A</p>. Record B is <p>COL amazonbasics 13 3 inch laptop sleeve black carrying cases page 10 office outlet express, COL the amazonbasics 13 3 inch laptop sleeve provides stylish protection for your laptop or ultrabook protect your laptop from bumps and scratches, COL amazonbasics</p>. Given the attributes of the two records, are they the same?
Record A is <p>COL nike air zoom structure 19 para mujer violeta azul zapatillas, COL N/A, COL N/A</p>. Record B is <p>COL nike femme air zoom pegasus 33 violet blanc rose chaussures pour, COL unit s nike zoom air au talon et l avant pied pour plus de dynamismemesh tiss favorisant la circulation d air fraisc bles flywire maintenant le piedsemelle interm diaire en cushlon pour plus d amorti, COL N/A</p>. Given the attributes of the two records, are they the same?
Record A is <p>COL canon 1133b001aa cb 2lx battery charger from solid signal, COL the canon cb 2lx compact battery charger is designed to take full advantage of high capacity rechargeable batteries it has been specially designed to charge the canon nb 5l battery, COL canon</p>. Record B is <p>COL cnd1133b001aa canon cb 2lx battery charger camera photo accessories page 2121 all tech toys, COL the cb 2lx battery charger charges canon nb 5l batteries allowing you to charge an additional battery for your digital camera, COL canon</p>. Given the attributes of the two records, are they the same?
Record A is <p>COL sql/xml is making good progress, COL a eisenberg , j melton</p>. Record B is <p>COL sql/xml is making good progress, COL a eisenberg , j melton</p>. Given the attributes of the two records, are they the same?
Record A is <p>COL Takin' My Time (Kiss My Amps Live), COL Tom Petty and the Heartbreakers, COL Kiss My Amps Live, COL 2011</p>. Record B is <p>COL 005-Nowhere, ca, COL The Sore Thumbs, COL Listen Up!! (2006), COL N/A</p>. Given the attributes of the two records, are they the same?
The size of the row level concatenation for training, validation, and test are: 6000, 12056, 12291
1060 out of 11135 data samples are filtered.
679 out of 12056 data samples are filtered.
The training phase starts from here.
The size of the training and validation datasets are: 10075, 11377
Here is the configuration for the experiment:
	seed: 42	base_model: gpt2	dataset_name: wdc-watches	mode: mode1 	max_len: 350	lr: 2e-05	batch_size: 32	patience: 6	p_start: 20
Epoch: 1 | Train Loss: 0.4097 | Valid Loss: 0.1644 | Train acc: 82.21 | Valid acc: 93.95 | Train f1: 76.73 | Valid f1: 89.07 | Train Time: 128.61311721801758 secs
The best model is updated at epoch: 1 with f1 score 0.8906955736224029
Epoch: 2 | Train Loss: 0.2433 | Valid Loss: 0.1094 | Train acc: 90.22 | Valid acc: 95.95 | Train f1: 87.84 | Valid f1: 92.83 | Train Time: 128.23047804832458 secs
The best model is updated at epoch: 2 with f1 score 0.9282550930026572
Epoch: 3 | Train Loss: 0.1904 | Valid Loss: 0.1608 | Train acc: 92.46 | Valid acc: 95.20 | Train f1: 90.73 | Valid f1: 91.50 | Train Time: 127.50600099563599 secs
Epoch: 4 | Train Loss: 0.1580 | Valid Loss: 0.0972 | Train acc: 94.14 | Valid acc: 96.30 | Train f1: 92.84 | Valid f1: 93.25 | Train Time: 127.63806247711182 secs
The best model is updated at epoch: 4 with f1 score 0.9324817518248175
Epoch: 5 | Train Loss: 0.1354 | Valid Loss: 0.1018 | Train acc: 94.90 | Valid acc: 96.45 | Train f1: 93.80 | Valid f1: 93.59 | Train Time: 127.92951607704163 secs
The best model is updated at epoch: 5 with f1 score 0.935862691960253
Epoch: 6 | Train Loss: 0.1119 | Valid Loss: 0.1759 | Train acc: 95.86 | Valid acc: 95.60 | Train f1: 94.97 | Valid f1: 92.59 | Train Time: 127.44898962974548 secs
Epoch: 7 | Train Loss: 0.0890 | Valid Loss: 0.1946 | Train acc: 96.90 | Valid acc: 96.05 | Train f1: 96.25 | Valid f1: 92.93 | Train Time: 126.2640380859375 secs
Epoch: 8 | Train Loss: 0.0778 | Valid Loss: 0.2569 | Train acc: 97.15 | Valid acc: 95.40 | Train f1: 96.55 | Valid f1: 91.81 | Train Time: 127.2623724937439 secs
Epoch: 9 | Train Loss: 0.0726 | Valid Loss: 0.2544 | Train acc: 97.59 | Valid acc: 95.85 | Train f1: 97.07 | Valid f1: 92.49 | Train Time: 128.4118528366089 secs
Epoch: 10 | Train Loss: 0.0636 | Valid Loss: 0.2520 | Train acc: 97.96 | Valid acc: 95.75 | Train f1: 97.53 | Valid f1: 92.84 | Train Time: 126.4355456829071 secs
Epoch: 11 | Train Loss: 0.0554 | Valid Loss: 0.3443 | Train acc: 98.36 | Valid acc: 94.75 | Train f1: 98.01 | Valid f1: 90.63 | Train Time: 128.90872502326965 secs
Epoch: 12 | Train Loss: 0.0541 | Valid Loss: 0.1738 | Train acc: 98.53 | Valid acc: 96.95 | Train f1: 98.22 | Valid f1: 94.49 | Train Time: 127.965172290802 secs
The best model is updated at epoch: 12 with f1 score 0.9448961156278229
Epoch: 13 | Train Loss: 0.0407 | Valid Loss: 0.2251 | Train acc: 98.85 | Valid acc: 96.70 | Train f1: 98.61 | Valid f1: 94.26 | Train Time: 128.37273740768433 secs
Epoch: 14 | Train Loss: 0.0341 | Valid Loss: 0.3984 | Train acc: 99.00 | Valid acc: 95.10 | Train f1: 98.79 | Valid f1: 91.20 | Train Time: 128.83673357963562 secs
Epoch: 15 | Train Loss: 0.0401 | Valid Loss: 0.3768 | Train acc: 98.85 | Valid acc: 95.30 | Train f1: 98.61 | Valid f1: 91.81 | Train Time: 127.29790782928467 secs
Epoch: 16 | Train Loss: 0.0321 | Valid Loss: 0.2676 | Train acc: 99.08 | Valid acc: 96.40 | Train f1: 98.88 | Valid f1: 93.73 | Train Time: 128.2017970085144 secs
Epoch: 17 | Train Loss: 0.0283 | Valid Loss: 0.3873 | Train acc: 99.21 | Valid acc: 95.30 | Train f1: 99.04 | Valid f1: 92.01 | Train Time: 127.42700862884521 secs
Epoch: 18 | Train Loss: 0.0210 | Valid Loss: 0.3520 | Train acc: 99.40 | Valid acc: 95.90 | Train f1: 99.28 | Valid f1: 92.50 | Train Time: 128.19464111328125 secs
Epoch: 19 | Train Loss: 0.0276 | Valid Loss: 0.3438 | Train acc: 99.35 | Valid acc: 95.90 | Train f1: 99.22 | Valid f1: 92.53 | Train Time: 128.43016123771667 secs
Epoch: 20 | Train Loss: 0.0268 | Valid Loss: 0.2543 | Train acc: 99.39 | Valid acc: 96.70 | Train f1: 99.27 | Valid f1: 94.10 | Train Time: 127.17915654182434 secs
Epoch: 21 | Train Loss: 0.0215 | Valid Loss: 0.2868 | Train acc: 99.46 | Valid acc: 96.40 | Train f1: 99.35 | Valid f1: 93.50 | Train Time: 127.90320873260498 secs
Epoch: 22 | Train Loss: 0.0183 | Valid Loss: 0.4285 | Train acc: 99.47 | Valid acc: 94.95 | Train f1: 99.36 | Valid f1: 91.32 | Train Time: 128.05032205581665 secs
Early stopping at epoch: 22
The training phase is finished.
Start the evaluation phase.
0 out of 1100 data samples are filtered.
trainable params: 124441344
--------------------------------------------------
Experiment to leave the wdc-cameras dataset out with attr+row as training data.
The model will be trained on the mixture of attribute and row level data.
The training set size of wdc-computers is larger than 1200, we will do down-sampling with automl_filter to maximally 1200 pairs.
The training set size of wdc-shoes is larger than 1200, we will do down-sampling with automl_filter to maximally 1200 pairs.
The training set size of wdc-watches is larger than 1200, we will do down-sampling with automl_filter to maximally 1200 pairs.
The training set size of dbgo is larger than 1200, we will do down-sampling with automl_filter to maximally 1200 pairs.
The training set size of music is larger than 1200, we will do down-sampling with automl_filter to maximally 1200 pairs.
Examples(row level) after the serialization are:

Record A is <p>COL targus notebook backpac 15 4 zwart grijs prijzen tweakers, COL N/A, COL N/A</p>. Record B is <p>COL amazonbasics 13 3 inch laptop sleeve black carrying cases page 10 office outlet express, COL the amazonbasics 13 3 inch laptop sleeve provides stylish protection for your laptop or ultrabook protect your laptop from bumps and scratches, COL amazonbasics</p>. Given the attributes of the two records, are they the same?
Record A is <p>COL nike air zoom structure 19 para mujer violeta azul zapatillas, COL N/A, COL N/A</p>. Record B is <p>COL nike femme air zoom pegasus 33 violet blanc rose chaussures pour, COL unit s nike zoom air au talon et l avant pied pour plus de dynamismemesh tiss favorisant la circulation d air fraisc bles flywire maintenant le piedsemelle interm diaire en cushlon pour plus d amorti, COL N/A</p>. Given the attributes of the two records, are they the same?
Record A is <p>COL junghans men s meister chronoscope automatic chronograph watch 027 4324 44 shop com, COL meister is junghans expression of the style of their classic watches while staying true to the principles of the finest materials and technological improvements refined aesthetics reminiscent of the watches designed by anton ziegler for the brand between 1930 and 1960 inside the watch is an automatic self winding chronograph j880 2 movement with 30 minute and 12 hour counters for the chronograph as well as sub second and day and date function this is displayed on a sunray brushed dark grey dial with hour and minutes marked clearly and simply the case is a stainless steel construction featuring exhibition case back with curved sicralan coated hard plexiglass true to the original giving it an elegant curvature to the dial the watch fastens on a 9 link stainless steel bracelet polished and matte finished for a perfect accompaniment to the case and dial, COL N/A</p>. Record B is <p>COL men s chronograph 1972 chronoscope solar junghans nur 749 00, COL N/A, COL junghans</p>. Given the attributes of the two records, are they the same?
Record A is <p>COL sql/xml is making good progress, COL a eisenberg , j melton</p>. Record B is <p>COL sql/xml is making good progress, COL a eisenberg , j melton</p>. Given the attributes of the two records, are they the same?
Record A is <p>COL Takin' My Time (Kiss My Amps Live), COL Tom Petty and the Heartbreakers, COL Kiss My Amps Live, COL 2011</p>. Record B is <p>COL 005-Nowhere, ca, COL The Sore Thumbs, COL Listen Up!! (2006), COL N/A</p>. Given the attributes of the two records, are they the same?
The size of the row level concatenation for training, validation, and test are: 6000, 12441, 12291
1255 out of 11061 data samples are filtered.
946 out of 12441 data samples are filtered.
The training phase starts from here.
The size of the training and validation datasets are: 9806, 11495
Here is the configuration for the experiment:
	seed: 42	base_model: gpt2	dataset_name: wdc-cameras	mode: mode1 	max_len: 350	lr: 2e-05	batch_size: 32	patience: 6	p_start: 20
Epoch: 1 | Train Loss: 0.4537 | Valid Loss: 0.1539 | Train acc: 78.11 | Valid acc: 94.65 | Train f1: 71.13 | Valid f1: 89.86 | Train Time: 129.03779816627502 secs
The best model is updated at epoch: 1 with f1 score 0.8985781990521327
Epoch: 2 | Train Loss: 0.2493 | Valid Loss: 0.1311 | Train acc: 89.64 | Valid acc: 95.45 | Train f1: 87.17 | Valid f1: 91.63 | Train Time: 128.9138650894165 secs
The best model is updated at epoch: 2 with f1 score 0.9162833486660533
Epoch: 3 | Train Loss: 0.1983 | Valid Loss: 0.1235 | Train acc: 91.95 | Valid acc: 95.20 | Train f1: 90.19 | Valid f1: 91.81 | Train Time: 128.86918568611145 secs
The best model is updated at epoch: 3 with f1 score 0.9180887372013652
Epoch: 4 | Train Loss: 0.1570 | Valid Loss: 0.1225 | Train acc: 93.83 | Valid acc: 95.85 | Train f1: 92.51 | Valid f1: 92.67 | Train Time: 129.14928722381592 secs
The best model is updated at epoch: 4 with f1 score 0.9267431597528685
Epoch: 5 | Train Loss: 0.1366 | Valid Loss: 0.1074 | Train acc: 94.64 | Valid acc: 96.55 | Train f1: 93.52 | Valid f1: 93.66 | Train Time: 128.49262523651123 secs
The best model is updated at epoch: 5 with f1 score 0.9366391184573003
Epoch: 6 | Train Loss: 0.1104 | Valid Loss: 0.1736 | Train acc: 95.78 | Valid acc: 95.10 | Train f1: 94.91 | Valid f1: 91.31 | Train Time: 129.00197649002075 secs
Epoch: 7 | Train Loss: 0.0920 | Valid Loss: 0.1704 | Train acc: 96.64 | Valid acc: 96.35 | Train f1: 95.96 | Valid f1: 93.61 | Train Time: 128.40443468093872 secs
Epoch: 8 | Train Loss: 0.0843 | Valid Loss: 0.1229 | Train acc: 97.23 | Valid acc: 96.20 | Train f1: 96.67 | Valid f1: 93.37 | Train Time: 128.05392980575562 secs
Epoch: 9 | Train Loss: 0.0690 | Valid Loss: 0.1740 | Train acc: 97.72 | Valid acc: 96.35 | Train f1: 97.26 | Valid f1: 92.97 | Train Time: 127.35993385314941 secs
Epoch: 10 | Train Loss: 0.0624 | Valid Loss: 0.1279 | Train acc: 97.95 | Valid acc: 96.85 | Train f1: 97.54 | Valid f1: 94.43 | Train Time: 128.6760196685791 secs
The best model is updated at epoch: 10 with f1 score 0.9442970822281167
Epoch: 11 | Train Loss: 0.0484 | Valid Loss: 0.2539 | Train acc: 98.42 | Valid acc: 95.70 | Train f1: 98.10 | Valid f1: 92.86 | Train Time: 128.55679726600647 secs
Epoch: 12 | Train Loss: 0.0408 | Valid Loss: 0.1474 | Train acc: 98.73 | Valid acc: 96.90 | Train f1: 98.47 | Valid f1: 94.66 | Train Time: 129.49951195716858 secs
The best model is updated at epoch: 12 with f1 score 0.946551724137931
Epoch: 13 | Train Loss: 0.0373 | Valid Loss: 0.2100 | Train acc: 98.92 | Valid acc: 96.45 | Train f1: 98.70 | Valid f1: 93.47 | Train Time: 129.74776482582092 secs
Epoch: 14 | Train Loss: 0.0398 | Valid Loss: 0.2008 | Train acc: 98.93 | Valid acc: 96.40 | Train f1: 98.71 | Valid f1: 93.74 | Train Time: 128.2181694507599 secs
Epoch: 15 | Train Loss: 0.0297 | Valid Loss: 0.2308 | Train acc: 99.07 | Valid acc: 96.90 | Train f1: 98.89 | Valid f1: 94.34 | Train Time: 128.41273760795593 secs
Epoch: 16 | Train Loss: 0.0303 | Valid Loss: 0.3138 | Train acc: 99.11 | Valid acc: 95.80 | Train f1: 98.93 | Valid f1: 92.64 | Train Time: 129.17398810386658 secs
Epoch: 17 | Train Loss: 0.0276 | Valid Loss: 0.3409 | Train acc: 99.20 | Valid acc: 95.35 | Train f1: 99.04 | Valid f1: 91.36 | Train Time: 128.61911869049072 secs
Epoch: 18 | Train Loss: 0.0255 | Valid Loss: 0.2787 | Train acc: 99.34 | Valid acc: 96.40 | Train f1: 99.20 | Valid f1: 93.65 | Train Time: 128.33555364608765 secs
Epoch: 19 | Train Loss: 0.0235 | Valid Loss: 0.2470 | Train acc: 99.34 | Valid acc: 96.65 | Train f1: 99.20 | Valid f1: 93.95 | Train Time: 129.19391059875488 secs
Epoch: 20 | Train Loss: 0.0222 | Valid Loss: 0.3030 | Train acc: 99.38 | Valid acc: 96.15 | Train f1: 99.25 | Valid f1: 93.22 | Train Time: 128.42397475242615 secs
Epoch: 21 | Train Loss: 0.0226 | Valid Loss: 0.2650 | Train acc: 99.37 | Valid acc: 96.55 | Train f1: 99.24 | Valid f1: 93.83 | Train Time: 129.81284642219543 secs
Epoch: 22 | Train Loss: 0.0177 | Valid Loss: 0.3451 | Train acc: 99.51 | Valid acc: 96.00 | Train f1: 99.41 | Valid f1: 92.65 | Train Time: 129.46168494224548 secs
Early stopping at epoch: 22
The training phase is finished.
Start the evaluation phase.
0 out of 1100 data samples are filtered.
trainable params: 124441344
--------------------------------------------------
Experiment to leave the dbgo dataset out with attr+row as training data.
The model will be trained on the mixture of attribute and row level data.
The training set size of wdc-computers is larger than 1200, we will do down-sampling with automl_filter to maximally 1200 pairs.
The training set size of wdc-shoes is larger than 1200, we will do down-sampling with automl_filter to maximally 1200 pairs.
The training set size of wdc-watches is larger than 1200, we will do down-sampling with automl_filter to maximally 1200 pairs.
The training set size of wdc-cameras is larger than 1200, we will do down-sampling with automl_filter to maximally 1200 pairs.
The training set size of music is larger than 1200, we will do down-sampling with automl_filter to maximally 1200 pairs.
Examples(row level) after the serialization are:

Record A is <p>COL targus notebook backpac 15 4 zwart grijs prijzen tweakers, COL N/A, COL N/A</p>. Record B is <p>COL amazonbasics 13 3 inch laptop sleeve black carrying cases page 10 office outlet express, COL the amazonbasics 13 3 inch laptop sleeve provides stylish protection for your laptop or ultrabook protect your laptop from bumps and scratches, COL amazonbasics</p>. Given the attributes of the two records, are they the same?
Record A is <p>COL nike air zoom structure 19 para mujer violeta azul zapatillas, COL N/A, COL N/A</p>. Record B is <p>COL nike femme air zoom pegasus 33 violet blanc rose chaussures pour, COL unit s nike zoom air au talon et l avant pied pour plus de dynamismemesh tiss favorisant la circulation d air fraisc bles flywire maintenant le piedsemelle interm diaire en cushlon pour plus d amorti, COL N/A</p>. Given the attributes of the two records, are they the same?
Record A is <p>COL junghans men s meister chronoscope automatic chronograph watch 027 4324 44 shop com, COL meister is junghans expression of the style of their classic watches while staying true to the principles of the finest materials and technological improvements refined aesthetics reminiscent of the watches designed by anton ziegler for the brand between 1930 and 1960 inside the watch is an automatic self winding chronograph j880 2 movement with 30 minute and 12 hour counters for the chronograph as well as sub second and day and date function this is displayed on a sunray brushed dark grey dial with hour and minutes marked clearly and simply the case is a stainless steel construction featuring exhibition case back with curved sicralan coated hard plexiglass true to the original giving it an elegant curvature to the dial the watch fastens on a 9 link stainless steel bracelet polished and matte finished for a perfect accompaniment to the case and dial, COL N/A</p>. Record B is <p>COL men s chronograph 1972 chronoscope solar junghans nur 749 00, COL N/A, COL junghans</p>. Given the attributes of the two records, are they the same?
Record A is <p>COL canon 1133b001aa cb 2lx battery charger from solid signal, COL the canon cb 2lx compact battery charger is designed to take full advantage of high capacity rechargeable batteries it has been specially designed to charge the canon nb 5l battery, COL canon</p>. Record B is <p>COL cnd1133b001aa canon cb 2lx battery charger camera photo accessories page 2121 all tech toys, COL the cb 2lx battery charger charges canon nb 5l batteries allowing you to charge an additional battery for your digital camera, COL canon</p>. Given the attributes of the two records, are they the same?
Record A is <p>COL Takin' My Time (Kiss My Amps Live), COL Tom Petty and the Heartbreakers, COL Kiss My Amps Live, COL 2011</p>. Record B is <p>COL 005-Nowhere, ca, COL The Sore Thumbs, COL Listen Up!! (2006), COL N/A</p>. Given the attributes of the two records, are they the same?
The size of the row level concatenation for training, validation, and test are: 6000, 7545, 7649
1537 out of 10395 data samples are filtered.
1178 out of 7545 data samples are filtered.
The training phase starts from here.
The size of the training and validation datasets are: 8858, 6367
Here is the configuration for the experiment:
	seed: 42	base_model: gpt2	dataset_name: dbgo	mode: mode1 	max_len: 350	lr: 2e-05	batch_size: 32	patience: 6	p_start: 20
Epoch: 1 | Train Loss: 0.4812 | Valid Loss: 0.1721 | Train acc: 75.54 | Valid acc: 93.75 | Train f1: 65.81 | Valid f1: 90.96 | Train Time: 121.0640549659729 secs
The best model is updated at epoch: 1 with f1 score 0.9096167751265365
Epoch: 2 | Train Loss: 0.2735 | Valid Loss: 0.1297 | Train acc: 88.63 | Valid acc: 94.70 | Train f1: 85.62 | Valid f1: 92.30 | Train Time: 120.47864842414856 secs
The best model is updated at epoch: 2 with f1 score 0.9229651162790697
Epoch: 3 | Train Loss: 0.2150 | Valid Loss: 0.1624 | Train acc: 90.91 | Valid acc: 93.75 | Train f1: 88.59 | Valid f1: 90.59 | Train Time: 120.62636733055115 secs
Epoch: 4 | Train Loss: 0.1841 | Valid Loss: 0.0896 | Train acc: 92.39 | Valid acc: 96.70 | Train f1: 90.57 | Valid f1: 95.13 | Train Time: 120.29142642021179 secs
The best model is updated at epoch: 4 with f1 score 0.9513274336283186
Epoch: 5 | Train Loss: 0.1560 | Valid Loss: 0.1571 | Train acc: 93.58 | Valid acc: 94.25 | Train f1: 92.08 | Valid f1: 91.96 | Train Time: 121.29058837890625 secs
Epoch: 6 | Train Loss: 0.1357 | Valid Loss: 0.1339 | Train acc: 94.84 | Valid acc: 95.60 | Train f1: 93.65 | Valid f1: 93.65 | Train Time: 119.9563581943512 secs
Epoch: 7 | Train Loss: 0.1114 | Valid Loss: 0.1560 | Train acc: 96.05 | Valid acc: 96.30 | Train f1: 95.16 | Valid f1: 94.63 | Train Time: 120.912926197052 secs
Epoch: 8 | Train Loss: 0.1027 | Valid Loss: 0.1310 | Train acc: 96.23 | Valid acc: 96.05 | Train f1: 95.40 | Valid f1: 93.99 | Train Time: 120.68421387672424 secs
Epoch: 9 | Train Loss: 0.0849 | Valid Loss: 0.1359 | Train acc: 97.17 | Valid acc: 96.85 | Train f1: 96.54 | Valid f1: 95.35 | Train Time: 119.89014291763306 secs
The best model is updated at epoch: 9 with f1 score 0.9535055350553505
Epoch: 10 | Train Loss: 0.0711 | Valid Loss: 0.2409 | Train acc: 97.74 | Valid acc: 95.05 | Train f1: 97.24 | Valid f1: 92.94 | Train Time: 120.05125093460083 secs
Epoch: 11 | Train Loss: 0.0640 | Valid Loss: 0.1374 | Train acc: 97.96 | Valid acc: 96.55 | Train f1: 97.51 | Valid f1: 94.97 | Train Time: 121.59748697280884 secs
Epoch: 12 | Train Loss: 0.0560 | Valid Loss: 0.2500 | Train acc: 98.23 | Valid acc: 95.25 | Train f1: 97.83 | Valid f1: 93.12 | Train Time: 120.15993332862854 secs
Epoch: 13 | Train Loss: 0.0601 | Valid Loss: 0.2147 | Train acc: 98.17 | Valid acc: 95.55 | Train f1: 97.77 | Valid f1: 93.31 | Train Time: 120.47641730308533 secs
Epoch: 14 | Train Loss: 0.0487 | Valid Loss: 0.2191 | Train acc: 98.52 | Valid acc: 96.40 | Train f1: 98.19 | Valid f1: 94.58 | Train Time: 121.20077419281006 secs
Epoch: 15 | Train Loss: 0.0447 | Valid Loss: 0.3014 | Train acc: 98.70 | Valid acc: 95.65 | Train f1: 98.42 | Valid f1: 93.89 | Train Time: 120.73103904724121 secs
Epoch: 16 | Train Loss: 0.0327 | Valid Loss: 0.2295 | Train acc: 99.04 | Valid acc: 96.90 | Train f1: 98.83 | Valid f1: 95.32 | Train Time: 120.97470879554749 secs
Epoch: 17 | Train Loss: 0.0329 | Valid Loss: 0.2689 | Train acc: 99.15 | Valid acc: 96.05 | Train f1: 98.97 | Valid f1: 94.07 | Train Time: 120.53208088874817 secs
Epoch: 18 | Train Loss: 0.0275 | Valid Loss: 0.2429 | Train acc: 99.14 | Valid acc: 96.25 | Train f1: 98.95 | Valid f1: 94.46 | Train Time: 121.21441316604614 secs
Epoch: 19 | Train Loss: 0.0274 | Valid Loss: 0.2714 | Train acc: 99.22 | Valid acc: 95.90 | Train f1: 99.05 | Valid f1: 93.93 | Train Time: 121.24940180778503 secs
Epoch: 20 | Train Loss: 0.0252 | Valid Loss: 0.2433 | Train acc: 99.36 | Valid acc: 96.80 | Train f1: 99.21 | Valid f1: 95.07 | Train Time: 121.69475769996643 secs
Epoch: 21 | Train Loss: 0.0274 | Valid Loss: 0.2494 | Train acc: 99.29 | Valid acc: 96.50 | Train f1: 99.13 | Valid f1: 94.88 | Train Time: 121.0261721611023 secs
Epoch: 22 | Train Loss: 0.0213 | Valid Loss: 0.2846 | Train acc: 99.45 | Valid acc: 96.30 | Train f1: 99.33 | Valid f1: 94.59 | Train Time: 120.44542193412781 secs
Early stopping at epoch: 22
The training phase is finished.
Start the evaluation phase.
0 out of 1100 data samples are filtered.
trainable params: 124441344
--------------------------------------------------
Experiment to leave the music dataset out with attr+row as training data.
The model will be trained on the mixture of attribute and row level data.
The training set size of wdc-computers is larger than 1200, we will do down-sampling with automl_filter to maximally 1200 pairs.
The training set size of wdc-shoes is larger than 1200, we will do down-sampling with automl_filter to maximally 1200 pairs.
The training set size of wdc-watches is larger than 1200, we will do down-sampling with automl_filter to maximally 1200 pairs.
The training set size of wdc-cameras is larger than 1200, we will do down-sampling with automl_filter to maximally 1200 pairs.
The training set size of dbgo is larger than 1200, we will do down-sampling with automl_filter to maximally 1200 pairs.
Examples(row level) after the serialization are:

Record A is <p>COL targus notebook backpac 15 4 zwart grijs prijzen tweakers, COL N/A, COL N/A</p>. Record B is <p>COL amazonbasics 13 3 inch laptop sleeve black carrying cases page 10 office outlet express, COL the amazonbasics 13 3 inch laptop sleeve provides stylish protection for your laptop or ultrabook protect your laptop from bumps and scratches, COL amazonbasics</p>. Given the attributes of the two records, are they the same?
Record A is <p>COL nike air zoom structure 19 para mujer violeta azul zapatillas, COL N/A, COL N/A</p>. Record B is <p>COL nike femme air zoom pegasus 33 violet blanc rose chaussures pour, COL unit s nike zoom air au talon et l avant pied pour plus de dynamismemesh tiss favorisant la circulation d air fraisc bles flywire maintenant le piedsemelle interm diaire en cushlon pour plus d amorti, COL N/A</p>. Given the attributes of the two records, are they the same?
Record A is <p>COL junghans men s meister chronoscope automatic chronograph watch 027 4324 44 shop com, COL meister is junghans expression of the style of their classic watches while staying true to the principles of the finest materials and technological improvements refined aesthetics reminiscent of the watches designed by anton ziegler for the brand between 1930 and 1960 inside the watch is an automatic self winding chronograph j880 2 movement with 30 minute and 12 hour counters for the chronograph as well as sub second and day and date function this is displayed on a sunray brushed dark grey dial with hour and minutes marked clearly and simply the case is a stainless steel construction featuring exhibition case back with curved sicralan coated hard plexiglass true to the original giving it an elegant curvature to the dial the watch fastens on a 9 link stainless steel bracelet polished and matte finished for a perfect accompaniment to the case and dial, COL N/A</p>. Record B is <p>COL men s chronograph 1972 chronoscope solar junghans nur 749 00, COL N/A, COL junghans</p>. Given the attributes of the two records, are they the same?
Record A is <p>COL canon 1133b001aa cb 2lx battery charger from solid signal, COL the canon cb 2lx compact battery charger is designed to take full advantage of high capacity rechargeable batteries it has been specially designed to charge the canon nb 5l battery, COL canon</p>. Record B is <p>COL cnd1133b001aa canon cb 2lx battery charger camera photo accessories page 2121 all tech toys, COL the cb 2lx battery charger charges canon nb 5l batteries allowing you to charge an additional battery for your digital camera, COL canon</p>. Given the attributes of the two records, are they the same?
Record A is <p>COL sql/xml is making good progress, COL a eisenberg , j melton</p>. Record B is <p>COL sql/xml is making good progress, COL a eisenberg , j melton</p>. Given the attributes of the two records, are they the same?
The size of the row level concatenation for training, validation, and test are: 6000, 10037, 10141
1537 out of 8791 data samples are filtered.
1178 out of 10037 data samples are filtered.
The training phase starts from here.
The size of the training and validation datasets are: 7254, 8859
Here is the configuration for the experiment:
	seed: 42	base_model: gpt2	dataset_name: music	mode: mode1 	max_len: 350	lr: 2e-05	batch_size: 32	patience: 6	p_start: 20
Epoch: 1 | Train Loss: 0.5796 | Valid Loss: 0.1964 | Train acc: 74.43 | Valid acc: 92.70 | Train f1: 62.82 | Valid f1: 80.11 | Train Time: 100.04992866516113 secs
The best model is updated at epoch: 1 with f1 score 0.8010899182561307
Epoch: 2 | Train Loss: 0.3074 | Valid Loss: 0.1362 | Train acc: 87.61 | Valid acc: 95.05 | Train f1: 83.27 | Valid f1: 87.32 | Train Time: 100.74160385131836 secs
The best model is updated at epoch: 2 with f1 score 0.8732394366197183
Epoch: 3 | Train Loss: 0.2545 | Valid Loss: 0.2495 | Train acc: 89.80 | Valid acc: 90.50 | Train f1: 86.43 | Valid f1: 77.05 | Train Time: 101.06814956665039 secs
Epoch: 4 | Train Loss: 0.2053 | Valid Loss: 0.3137 | Train acc: 92.32 | Valid acc: 90.35 | Train f1: 89.85 | Valid f1: 76.32 | Train Time: 100.47092843055725 secs
Epoch: 5 | Train Loss: 0.1777 | Valid Loss: 0.2452 | Train acc: 93.05 | Valid acc: 92.90 | Train f1: 90.91 | Valid f1: 82.07 | Train Time: 101.13677406311035 secs
Epoch: 6 | Train Loss: 0.1400 | Valid Loss: 0.1570 | Train acc: 94.94 | Valid acc: 95.90 | Train f1: 93.42 | Valid f1: 87.69 | Train Time: 100.41746354103088 secs
The best model is updated at epoch: 6 with f1 score 0.8768768768768769
Epoch: 7 | Train Loss: 0.1221 | Valid Loss: 0.2146 | Train acc: 95.60 | Valid acc: 94.70 | Train f1: 94.29 | Valid f1: 85.64 | Train Time: 100.71616101264954 secs
Epoch: 8 | Train Loss: 0.1079 | Valid Loss: 0.1887 | Train acc: 96.14 | Valid acc: 95.35 | Train f1: 94.99 | Valid f1: 86.92 | Train Time: 100.71115064620972 secs
Epoch: 9 | Train Loss: 0.0879 | Valid Loss: 0.2885 | Train acc: 96.91 | Valid acc: 94.20 | Train f1: 96.00 | Valid f1: 84.28 | Train Time: 101.14314484596252 secs
Epoch: 10 | Train Loss: 0.0765 | Valid Loss: 0.3855 | Train acc: 97.35 | Valid acc: 93.25 | Train f1: 96.57 | Valid f1: 82.26 | Train Time: 100.76458311080933 secs
Epoch: 11 | Train Loss: 0.0689 | Valid Loss: 0.3439 | Train acc: 97.93 | Valid acc: 94.45 | Train f1: 97.33 | Valid f1: 85.38 | Train Time: 100.82215690612793 secs
Epoch: 12 | Train Loss: 0.0651 | Valid Loss: 0.3227 | Train acc: 97.82 | Valid acc: 94.35 | Train f1: 97.18 | Valid f1: 84.67 | Train Time: 100.32704424858093 secs
Epoch: 13 | Train Loss: 0.0471 | Valid Loss: 0.4340 | Train acc: 98.51 | Valid acc: 94.75 | Train f1: 98.07 | Valid f1: 85.75 | Train Time: 100.65306401252747 secs
Epoch: 14 | Train Loss: 0.0498 | Valid Loss: 0.4028 | Train acc: 98.52 | Valid acc: 95.00 | Train f1: 98.09 | Valid f1: 86.74 | Train Time: 101.00447964668274 secs
Epoch: 15 | Train Loss: 0.0377 | Valid Loss: 0.3841 | Train acc: 98.87 | Valid acc: 95.20 | Train f1: 98.54 | Valid f1: 87.37 | Train Time: 100.84036040306091 secs
Epoch: 16 | Train Loss: 0.0355 | Valid Loss: 0.4937 | Train acc: 98.98 | Valid acc: 94.25 | Train f1: 98.68 | Valid f1: 84.97 | Train Time: 100.81096982955933 secs
Epoch: 17 | Train Loss: 0.0295 | Valid Loss: 0.5997 | Train acc: 99.15 | Valid acc: 93.10 | Train f1: 98.89 | Valid f1: 82.75 | Train Time: 100.80624532699585 secs
Epoch: 18 | Train Loss: 0.0320 | Valid Loss: 0.5526 | Train acc: 99.09 | Valid acc: 94.10 | Train f1: 98.82 | Valid f1: 84.01 | Train Time: 101.21352648735046 secs
Epoch: 19 | Train Loss: 0.0311 | Valid Loss: 0.4089 | Train acc: 99.10 | Valid acc: 95.40 | Train f1: 98.84 | Valid f1: 87.67 | Train Time: 100.65994453430176 secs
Epoch: 20 | Train Loss: 0.0249 | Valid Loss: 0.5841 | Train acc: 99.28 | Valid acc: 94.00 | Train f1: 99.07 | Valid f1: 84.81 | Train Time: 101.3430118560791 secs
Epoch: 21 | Train Loss: 0.0214 | Valid Loss: 0.5055 | Train acc: 99.37 | Valid acc: 94.70 | Train f1: 99.18 | Valid f1: 86.20 | Train Time: 101.50103330612183 secs
Epoch: 22 | Train Loss: 0.0200 | Valid Loss: 0.6431 | Train acc: 99.37 | Valid acc: 93.75 | Train f1: 99.18 | Valid f1: 83.18 | Train Time: 101.3803379535675 secs
Early stopping at epoch: 22
The training phase is finished.
Start the evaluation phase.
0 out of 1100 data samples are filtered.
